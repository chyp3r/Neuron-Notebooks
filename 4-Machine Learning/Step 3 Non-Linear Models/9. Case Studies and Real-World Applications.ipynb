{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Studies and Real-World Applications of Non-Linear Models\n",
    "\n",
    "In this section, we will explore how non-linear models like decision trees, random forests, neural networks, and others are applied to solve real-world problems. We will walk through a few case studies, examine the key steps, and highlight the use of non-linear models in various industries.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Case Study 1: Fraud Detection with Random Forests](#1-fraud-detection-with-random-forests)\n",
    "2. [Case Study 2: Image Classification with Neural Networks](#2-image-classification-with-neural-networks)\n",
    "3. [Case Study 3: Cancer Diagnosis with Support Vector Machines (SVM)](#3-cancer-diagnosis-with-svm)\n",
    "4. [Case Study 4: Predicting Customer Churn with Gradient Boosting Machines (GBMs)](#4-predicting-customer-churn-with-gbms)\n",
    "5. [Key Learnings](#5-key-learnings)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fraud Detection with Random Forests\n",
    "\n",
    "### Problem:\n",
    "Financial institutions use Random Forests to identify and predict fraudulent transactions. This problem involves analyzing historical transaction data and building models to detect fraudulent activities.\n",
    "\n",
    "### Steps Involved:\n",
    "- **Data collection**: Historical transaction data (e.g., customer ID, transaction amount, location, time).\n",
    "- **Preprocessing**: Handling missing values, encoding categorical variables.\n",
    "- **Model**: Random Forest Classifier is used to predict fraud (binary classification).\n",
    "- **Evaluation**: Metrics like precision, recall, and F1-score to assess performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"data\\fraud_dataset_example.csv\")\n",
    "\n",
    "print(len(data[data[\"isFraud\"] == 0]))\n",
    "print(len(data[data[\"isFraud\"] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"step\",\"nameOrig\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "cat_cols = data.select_dtypes([\"object\",\"category\"]).columns.to_list()\n",
    "num_cols = data.select_dtypes([\"int\",\"float\"]).columns.to_list()\n",
    "num_cols.remove(\"isFraud\")\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "for i in range(len(cat_cols)):\n",
    "\tdata[cat_cols[i]] = label_encoder.fit_transform(data[cat_cols[i]])\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "min_class = data[data[\"isFraud\"] == 1]\n",
    "maj_class = data[data[\"isFraud\"] == 0]\n",
    "\n",
    "oversample = resample(min_class,n_samples=len(maj_class),random_state=42,replace=True)\n",
    "oversampled_data = pd.concat([maj_class,oversample])\n",
    "\n",
    "X = oversampled_data.drop(columns=[\"isFraud\"])\n",
    "y = oversampled_data[\"isFraud\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test,y_pred)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = confusion_matrix(y_test,y_pred,normalize=\"true\")\n",
    "sns.heatmap(corr,annot=True,cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Classification with Neural Networks\n",
    "### Problem:\n",
    "Neural Networks are used in image classification tasks, such as recognizing objects in images or distinguishing between different image categories. For example, detecting various animals in a photo dataset.\n",
    "\n",
    "### Steps Involved:\n",
    "- Data collection: Large dataset of images (e.g., CIFAR-10, ImageNet).\n",
    "- Preprocessing: Image resizing, normalization.\n",
    "- Model: Convolutional Neural Networks (CNNs) for feature extraction and classification.\n",
    "- Evaluation: Accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NyNet,self).__init__()\n",
    "        self.cv1 = nn.Conv2d(in_channels=1,out_channels=4,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.cv2 = nn.Conv2d(in_channels=4,out_channels=16,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.fc1 = nn.Linear(in_features=16*7*7, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64,out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.cv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5),)])\n",
    "train_data = datasets.MNIST(\"./data\",train=True,download=False,transform=transform)\n",
    "test_data = datasets.MNIST(\"./data\",train=True,download=False,transform=transform)\n",
    "train_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=32,shuffle=False)\n",
    "model = NyNet()\n",
    "optimizer = optim.Adam(model.parameters(),lr=.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 1\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCH}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cancer Diagnosis with Support Vector Machines (SVM)\n",
    "### Problem:\n",
    "SVMs are used in healthcare to classify diseases based on medical records. One common application is diagnosing cancer based on features like tumor size, texture, and smoothness.\n",
    "\n",
    "### Steps Involved:\n",
    "- Data collection: Medical data with features of tumors.\n",
    "- Preprocessing: Normalization, feature scaling.\n",
    "- Model: Support Vector Classifier (SVC) for binary classification.\n",
    "- Evaluation: ROC curve, AUC score, confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"data\\breast-cancer.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1\n"
     ]
    }
   ],
   "source": [
    "num_cols = data.select_dtypes([\"int\",\"float\"]).columns.to_list()\n",
    "cat_cols = data.select_dtypes([\"string\",\"object\"]).columns.to_list()\n",
    "num_cols.remove(\"id\")\n",
    "print(len(num_cols),len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1        17.99         10.38          122.80   \n",
       "1      842517          1        20.57         17.77          132.90   \n",
       "2    84300903          1        19.69         21.25          130.00   \n",
       "3    84348301          1        11.42         20.38           77.58   \n",
       "4    84358402          1        20.29         14.34          135.10   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1        21.56         22.39          142.00   \n",
       "565    926682          1        20.13         28.25          131.20   \n",
       "566    926954          1        16.60         28.08          108.30   \n",
       "567    927241          1        20.60         29.33          140.10   \n",
       "568     92751          0         7.76         24.54           47.92   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                0.14710  ...        25.380          17.33           184.60   \n",
       "1                0.07017  ...        24.990          23.41           158.80   \n",
       "2                0.12790  ...        23.570          25.53           152.50   \n",
       "3                0.10520  ...        14.910          26.50            98.87   \n",
       "4                0.10430  ...        22.540          16.67           152.20   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564              0.13890  ...        25.450          26.40           166.10   \n",
       "565              0.09791  ...        23.690          38.25           155.00   \n",
       "566              0.05302  ...        18.980          34.12           126.70   \n",
       "567              0.15200  ...        25.740          39.42           184.60   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data[\"diagnosis\"] = LabelEncoder().fit_transform(data[\"diagnosis\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1     1.097064     -2.073335        1.269934   \n",
       "1      842517          1     1.829821     -0.353632        1.685955   \n",
       "2    84300903          1     1.579888      0.456187        1.566503   \n",
       "3    84348301          1    -0.768909      0.253732       -0.592687   \n",
       "4    84358402          1     1.750297     -1.151816        1.776573   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1     2.110995      0.721473        2.060786   \n",
       "565    926682          1     1.704854      2.085134        1.615931   \n",
       "566    926954          1     0.702284      2.045574        0.672676   \n",
       "567    927241          1     1.838341      2.336457        1.982524   \n",
       "568     92751          0    -1.808401      1.221792       -1.814389   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     0.984375         1.568466          3.283515        2.652874   \n",
       "1     1.908708        -0.826962         -0.487072       -0.023846   \n",
       "2     1.558884         0.942210          1.052926        1.363478   \n",
       "3    -0.764464         3.283553          3.402909        1.915897   \n",
       "4     1.826229         0.280372          0.539340        1.371011   \n",
       "..         ...              ...               ...             ...   \n",
       "564   2.343856         1.041842          0.219060        1.947285   \n",
       "565   1.723842         0.102458         -0.017833        0.693043   \n",
       "566   0.577953        -0.840484         -0.038680        0.046588   \n",
       "567   1.735218         1.525767          3.272144        3.296944   \n",
       "568  -1.347789        -3.112085         -1.150752       -1.114873   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               2.532475  ...      1.886690      -1.359293         2.303601   \n",
       "1               0.548144  ...      1.805927      -0.369203         1.535126   \n",
       "2               2.037231  ...      1.511870      -0.023974         1.347475   \n",
       "3               1.451707  ...     -0.281464       0.133984        -0.249939   \n",
       "4               1.428493  ...      1.298575      -1.466770         1.338539   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564             2.320965  ...      1.901185       0.117700         1.752563   \n",
       "565             1.263669  ...      1.536720       2.047399         1.421940   \n",
       "566             0.105777  ...      0.561361       1.374854         0.579001   \n",
       "567             2.658866  ...      1.961239       2.237926         2.303601   \n",
       "568            -1.261820  ...     -1.410893       0.764190        -1.432735   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2.001237          1.307686           2.616665         2.109526   \n",
       "1      1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2      1.456285          0.527407           1.082932         0.854974   \n",
       "3     -0.550021          3.394275           3.893397         1.989588   \n",
       "4      1.220724          0.220556          -0.313395         0.613179   \n",
       "..          ...               ...                ...              ...   \n",
       "564    2.015301          0.378365          -0.273318         0.664512   \n",
       "565    1.494959         -0.691230          -0.394820         0.236573   \n",
       "566    0.427906         -0.809587           0.350735         0.326767   \n",
       "567    1.653171          1.430427           3.904848         3.197605   \n",
       "568   -1.075813         -1.859019          -1.207552        -1.305831   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                2.296076        2.750622                 1.937015  \n",
       "1                1.087084       -0.243890                 0.281190  \n",
       "2                1.955000        1.152255                 0.201391  \n",
       "3                2.175786        6.046041                 4.935010  \n",
       "4                0.729259       -0.868353                -0.397100  \n",
       "..                    ...             ...                      ...  \n",
       "564              1.629151       -1.360158                -0.709091  \n",
       "565              0.733827       -0.531855                -0.973978  \n",
       "566              0.414069       -1.104549                -0.318409  \n",
       "567              2.289985        1.919083                 2.219635  \n",
       "568             -1.745063       -0.048138                -0.751207  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicting Customer Churn with Gradient Boosting Machines (GBMs)\n",
    "### Problem:\n",
    "Businesses often use GBMs to predict customer churn by analyzing customer behavior and identifying customers who are likely to stop using a service.\n",
    "\n",
    "### Steps Involved:\n",
    "- Data collection: Customer interaction data, service usage, and demographics.\n",
    "- Preprocessing: Handling missing values, encoding categorical variables.\n",
    "- Model: GBM-based classifier (e.g., XGBoost or LightGBM).\n",
    "- Evaluation: Accuracy, precision, recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Learnings\n",
    "- Random Forests: Effective for classification tasks like fraud detection, offering good performance with minimal tuning.\n",
    "- Neural Networks: Widely used in image recognition and complex pattern recognition.\n",
    "- SVMs: Ideal for healthcare applications like cancer diagnosis where high-dimensional data and clear decision boundaries are present.\n",
    "- GBMs: Used for customer churn prediction due to their ability to handle large datasets with many features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
