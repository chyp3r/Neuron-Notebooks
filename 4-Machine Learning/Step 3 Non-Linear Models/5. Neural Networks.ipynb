{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Neural Networks are at the core of deep learning and have been highly successful in solving complex problems involving images, speech, and text. In this section, we will introduce the structure of a neural network, discuss key concepts such as neurons, activation functions, and layers, and implement a simple neural network using Python.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [What is a Neural Network?](#1-what-is-a-neural-network)\n",
    "2. [Structure of a Neural Network](#2-structure-of-a-neural-network)\n",
    "3. [Key Components of Neural Networks](#3-key-components-of-neural-networks)\n",
    "4. [Advantages and Disadvantages of Neural Networks](#4-advantages-and-disadvantages-of-neural-networks)\n",
    "5. [Use Cases of Neural Networks](#5-use-cases-of-neural-networks)\n",
    "6. [Implementing a Neural Network in Python](#6-implementing-a-neural-network-in-python)\n",
    "7. [Evaluating the Neural Network](#7-evaluating-the-neural-network)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Neural Network?\n",
    "\n",
    "A neural network is a computational model inspired by the human brain, consisting of layers of neurons that process data in a hierarchical manner. Neural networks are used for both classification and regression tasks and are especially effective for non-linear problems.\n",
    "\n",
    "### Key Points:\n",
    "- Neural networks consist of interconnected nodes called neurons.\n",
    "- These neurons are organized in layers: the input layer, hidden layers, and the output layer.\n",
    "- Neural networks use backpropagation for training, adjusting weights to minimize the error between predictions and true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Structure of a Neural Network\n",
    "The basic structure of a neural network consists of:\n",
    "\n",
    "- Input Layer: The layer that receives the input features.\n",
    "- Hidden Layers: Layers in between the input and output that perform complex computations.\n",
    "- Output Layer: The layer that outputs the predicted result (classification or regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture:\n",
    "- **Input Layer:** Takes the features from the dataset.\n",
    "- **Hidden Layer:** Each hidden layer applies weights to the inputs and passes them through an activation function.\n",
    "- **Output Layer:** Produces the final prediction based on the inputs from the hidden layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Key Components of Neural Networks\n",
    "1. Neurons: The basic units that process and transmit information in the network.\n",
    "2. Weights: Parameters that the network adjusts during training to learn patterns in the data.\n",
    "3. Bias: An additional parameter that allows the model to fit better to the data.\n",
    "4. Activation Functions: These introduce non-linearity into the network. Common activation functions include:\n",
    "\t- Sigmoid: Useful for binary classification problems.\n",
    "\t- ReLU (Rectified Linear Unit): Most widely used activation function for hidden layers.\n",
    "\t- Tanh: Another activation function that maps input between -1 and 1.\n",
    "5. Loss Function: Measures the difference between predicted and actual values.\n",
    "6. Backpropagation: The method by which the neural network updates its weights through gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advantages and Disadvantages of Neural Networks\n",
    "### Advantages:\n",
    "- **Powerful for Complex Data:** Neural networks can capture intricate patterns in large datasets, especially those with non-linear relationships.\n",
    "- **Adaptability:** Can be used for various tasks like classification, regression, and clustering.\n",
    "- **Scalability:** Easily scaled up with more layers and neurons (Deep Learning).\n",
    "\n",
    "### Disadvantages:\n",
    "- **Requires Large Datasets:** Neural networks need large amounts of data to perform well.\n",
    "- **Computationally Expensive:** Training a neural network, especially deep networks, requires significant computational power.\n",
    "- **Black Box Nature:** Neural networks can be difficult to interpret due to their complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use Cases of Neural Networks\n",
    "### Use Cases:\n",
    "- **Image Recognition:** Used in tasks like identifying objects in photos (e.g., convolutional neural networks for image classification).\n",
    "- **Natural Language Processing:** Applications like sentiment analysis, machine translation, and text generation.\n",
    "- **Speech Recognition:** Used in converting spoken language into text.\n",
    "- **Medical Diagnosis:** Neural networks are used for tasks like predicting diseases based on patient data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing a Neural Network in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\t\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN,self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=28*28,out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128,out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64,out_features=10)\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((.5,),(.5,))])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform) \n",
    "test_dataset = datasets.MNIST(root=\"./data\",train=False,download=True,transform=transform)\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=False)\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUMBER = 5\n",
    "\n",
    "for epoch in range(EPOCH_NUMBER):\n",
    "\tfor images,labels in train_loader:\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(images)\n",
    "\t\tloss = criterion(outputs,labels)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()  \n",
    "\tprint(f'Epoch [{epoch+1}/{EPOCH_NUMBER}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluating the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images,labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _ , predicts = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicts == labels).sum().item()    \n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'Accuracy of the model on the test dataset: {accuracy:.2f}%')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
