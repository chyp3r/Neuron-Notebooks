{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Supervised Learning Algorithms\n",
    "\n",
    "Supervised learning algorithms are widely used in various fields to solve classification and regression problems. These algorithms learn from labeled data to make predictions on unseen data.\n",
    "\n",
    "In this notebook, we will cover the most commonly used supervised learning algorithms, including:\n",
    "\n",
    "1. Linear Regression\n",
    "2. Logistic Regression\n",
    "3. Decision Trees\n",
    "4. Random Forests\n",
    "5. Support Vector Machines (SVM)\n",
    "6. k-Nearest Neighbors (k-NN)\n",
    "7. Naive Bayes\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Linear Regression](#1-linear-regression)\n",
    "2. [Logistic Regression](#2-logistic-regression)\n",
    "3. [Decision Trees](#3-decision-trees)\n",
    "4. [Random Forests](#4-random-forests)\n",
    "5. [Support Vector Machines (SVM)](#5-support-vector-machines)\n",
    "6. [k-Nearest Neighbors (k-NN)](#6-k-nearest-neighbors)\n",
    "7. [Naive Bayes](#7-naive-bayes)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression\n",
    "Linear Regression is used to predict a continuous target variable. The model assumes a linear relationship between the input features and the target. It's commonly used for tasks like predicting prices, quantities, or other numeric outcomes.\n",
    "\n",
    "### Usage Areas:\n",
    "- House price prediction\n",
    "- Stock price prediction\n",
    "- Sales forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.75481858 -15.5696545    6.52981107 -19.49595443   3.90695784\n",
      " -11.53111035   3.3177018   37.19618219  24.4335712  -14.34889541]\n",
      "MSE: 84.38555896440674\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X,y = make_regression(n_samples = 10,n_features=1,noise = 10,random_state = 42)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .3,random_state = 42)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "Logistic Regression is a classification algorithm used when the target variable is categorical. It models the probability that a given input belongs to a specific class. Itâ€™s commonly used for binary classification tasks.\n",
    "\n",
    "### Usage Areas:\n",
    "- Medical diagnoses (e.g., predicting whether a tumor is benign or malignant)\n",
    "- Fraud detection (e.g., predicting fraudulent transactions)\n",
    "- Marketing (e.g., customer conversion prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_classes=2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Trees\n",
    "Decision Trees work by splitting the data based on feature values to form a tree structure. They are useful for both classification and regression tasks and provide interpretable models.\n",
    "\n",
    "### Usage Areas:\n",
    "- Customer segmentation\n",
    "- Credit risk assessment\n",
    "- Recommendation systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_classification(n_classes=2,random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forests\n",
    "Random Forest is an ensemble learning algorithm that combines multiple decision trees to improve performance. It reduces overfitting and provides better accuracy for classification and regression tasks.\n",
    "\n",
    "### Usage Areas:\n",
    "- Stock market prediction\n",
    "- Medical diagnoses\n",
    "- Fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Support Vector Machines (SVM)\n",
    "SVM is a powerful classification algorithm that finds the optimal boundary (hyperplane) between classes. It is useful for both linear and non-linear classification using kernel functions.\n",
    "\n",
    "### Usage Areas:\n",
    "- Image recognition\n",
    "- Text classification\n",
    "- Bioinformatics (e.g., protein classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel = \"linear\",random_state = 42)\n",
    "svm_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. k-Nearest Neighbors (k-NN)\n",
    "k-NN is a simple classification algorithm that assigns a label to a data point based on the majority class among its k-nearest neighbors. It is non-parametric and requires no training phase.\n",
    "\n",
    "### Usage Areas:\n",
    "- Pattern recognition\n",
    "- Recommender systems\n",
    "- Medical diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Naive Bayes\n",
    "Naive Bayes is a probabilistic classifier based on Bayes' Theorem. It assumes that features are independent of each other. Despite this assumption, Naive Bayes performs well in many real-world applications, especially with large datasets.\n",
    "\n",
    "### Usage Areas:\n",
    "- Spam detection\n",
    "- Sentiment analysis\n",
    "- Document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
