{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools and Libraries for Machine Learning\n",
    "\n",
    "In machine learning, having the right tools and libraries is essential for efficient model development, deployment, and experimentation. This section will introduce some of the most popular machine learning libraries and tools, with descriptions of their usage areas, features, and code examples.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Scikit-learn](#1-scikit-learn)\n",
    "2. [TensorFlow](#2-tensorflow)\n",
    "3. [Keras](#3-keras)\n",
    "4. [PyTorch](#4-pytorch)\n",
    "5. [XGBoost](#5-xgboost)\n",
    "6. [LightGBM](#6-lightgbm)\n",
    "7. [Hyperopt](#7-hyperopt)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scikit-learn\n",
    "\n",
    "**Usage**: Classical machine learning models and data preprocessing.\n",
    "\n",
    "**Features**:\n",
    "- Wide range of machine learning algorithms (classification, regression, clustering).\n",
    "- Easy integration with NumPy and Pandas.\n",
    "- Tools for cross-validation, feature selection, and metrics evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris # load iris.csv from sklearn\n",
    "\n",
    "data = load_iris()\n",
    "X_train,X_test,y_train,y_test = train_test_split(data.data,data.target,test_size=.3,random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow\n",
    "**Usage**: \n",
    "Deep learning, large-scale machine learning models, and deployment.\n",
    "\n",
    "**Features**:\n",
    "- Extensive support for building and training neural networks.\n",
    "- TensorFlow Serving for deploying models.\n",
    "- Scalable for distributed computing and large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data is created for sklearn \n",
    "# If you want to show results for another models you must make something on data :)\n",
    "# or just wait for other lessons\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras\n",
    "**Usage**: \n",
    "High-level deep learning API that runs on top of TensorFlow.\n",
    "\n",
    "**Features**:\n",
    "- Simplifies the process of building neural networks.\n",
    "- Supports multiple backend engines (e.g., TensorFlow, Theano).\n",
    "- Easy-to-use interface for beginners and prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=4),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyTorch\n",
    "**Usage**: \n",
    "Deep learning, research, dynamic computational graphs.\n",
    "\n",
    "**Features**:\n",
    "- Dynamic computational graph, which is useful for research.\n",
    "- Extensive support for neural network development.\n",
    "- Strong community support and wide use in research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=4,out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64,out_features=3)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(),lr=.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost\n",
    "**Usage**: \n",
    "Gradient boosting for structured/tabular data.\n",
    "\n",
    "**Features**:\n",
    "- Efficient and accurate implementation of gradient boosting.\n",
    "- Support for handling missing values.\n",
    "- Great performance in competitions (e.g., Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {'objective': 'multi:softmax', 'num_class': 3}\n",
    "model = xgb.train(params, dtrain)\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LightGBM\n",
    "**Usage**: \n",
    "Gradient boosting for high-dimensional data.\n",
    "\n",
    "**Features**:\n",
    "- Faster training speed compared to XGBoost.\n",
    "- Efficient for large datasets.\n",
    "- Handles categorical features directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {'objective': 'multiclass', 'num_class': 3}\n",
    "model = lgb.train(params, train_data)\n",
    "\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperopt\n",
    "**Usage**: \n",
    "Hyperparameter optimization.\n",
    "\n",
    "**Features**:\n",
    "- Optimizes hyperparameters using search strategies like random search, grid  search, or Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "def objective(params):\n",
    "    return params['x'] ** 2 + params['y'] ** 2\n",
    "\n",
    "space = {\n",
    "    'x': hp.uniform('x', -10, 10),\n",
    "    'y': hp.uniform('y', -10, 10)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100)\n",
    "print(\"Best parameters:\", best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
