{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Linear Models\n",
    "\n",
    "In this section, we will focus on evaluating linear models using various metrics and techniques. Model evaluation helps us understand how well the model performs on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Why Evaluate Linear Models?](#1-why-evaluate-linear-models)\n",
    "2. [Train-Test Split](#2-train-test-split)\n",
    "3. [Evaluation Metrics for Regression](#3-evaluation-metrics-for-regression)\n",
    "    - Mean Absolute Error (MAE)\n",
    "    - Mean Squared Error (MSE)\n",
    "    - Root Mean Squared Error (RMSE)\n",
    "    - R-squared (R²)\n",
    "4. [Cross-Validation](#4-cross-validation)\n",
    "5. [Regularization Impact on Evaluation](#5-regularization-impact)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Evaluate Linear Models?\n",
    "\n",
    "Evaluating linear models is essential for understanding how well a model generalizes to unseen data. Overfitting or underfitting can lead to poor performance in real-world scenarios. Proper evaluation gives insights into the model's predictive power and robustness.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split\n",
    "\n",
    "Before evaluating the model, it's important to split the dataset into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_regression(n_samples=1000)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics for Regression\n",
    "### 3.1 Mean Absolute Error (MAE)\n",
    "The Mean Absolute Error is the average of the absolute differences between the actual and predicted values. It gives an idea of how far off the predictions are from the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Mean Squared Error (MSE)\n",
    "The Mean Squared Error measures the average of the squared differences between actual and predicted values. Squaring the errors gives more weight to larger errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Root Mean Squared Error (RMSE)\n",
    "The RMSE is the square root of the MSE. It provides an error metric in the same units as the target variable, making it more interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mse ** 0.5\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 R-squared (R²)\n",
    "R-squared measures the proportion of variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where 1 indicates a perfect fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared (R²):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation\n",
    "Cross-validation is a technique for assessing model performance by dividing the data into multiple subsets. Each subset is used as a test set once, and the model is trained on the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"Cross-validation MSE scores:\", -cv_scores)\n",
    "print(\"Average cross-validation MSE:\", -cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regularization Impact on Evaluation\n",
    "When evaluating regularized models like Ridge or Lasso, the regularization strength can impact the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "\n",
    "print(\"Ridge Regression MSE:\", ridge_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
